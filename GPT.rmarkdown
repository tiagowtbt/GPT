---
title: "GPT"
---

```{r}
library("readtext") #pacote para ler o texto
library("stringr")
library(torch)
library(tidyverse)
```


Primeiro temos que importar nossos dados

https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing#scrollTo=O6medjfRsLD9


```{r}
import <- readtext("input.txt") 

text <- enc2utf8(import$text)
nchar(text) # numero de caracteres no texto

#cat(text$text, "\n", sep = "")

vocab <- sort(unique(strsplit(text, "")[[1]])) # nosso vocabulario

cat(vocab)
#cat(substr(text, 1 ,1000), "\n", sep = "") # pri
rm(import)
```

```{r}
# criando os codificadores e decodificadores

index <- 1:length(vocab)
df <- data.frame(index, vocab)

encode <- function(char) {
  aux_1 <- as.vector(str_split_fixed(char, pattern = "", n = nchar(char)))
  aux_2 <- c()
  
  for (i in 1:length(aux_1)) {
    aux_2[length(aux_2) + 1] <- df$index[df$vocab == nth(aux_1, i)]
    
    
  }
  return(aux_2)
}

decode <- function(data) {
  
  aux_2 <- c()
  for (i in 1:length(data)) {
    aux_2[length(aux_2) + 1] <- df$vocab[df$index == as.integer(data[i])]
  }
  
  aux_2 <- paste(aux_2, collapse = " ")
  return(aux_2)
}

print(encode(substr(text, 1 ,1000)))

```

```{r}
data <- torch_tensor(encode(text), dtype = torch_long())

print(decode(data[1:1000]))

```

```{r}
n <- as.integer(0.9*(length(data)))

train_data <- data[1:n]
val_data <- data[n:length(data)]

```

```{r}
torch_manual_seed(1337)

block_size <- 8
batch_size <- 4


get_batch <- function(split) {
  if (split == "train") {
    
  }
  else data <- val_data
  
  ix <- torch_rand_int(0, length(data) - block_size, batch_size)
  for(i in ix:(ix + block_size)) {
    data[]
  }
  
  
  
}

x <- matrix()

data <- train_data
ix <- torch_randint(0, length(data) - block_size, batch_size)
  for(i in 1: batch_size) {
    aux <- as.array(data[as.numeric(ix[1]):(as.numeric(ix[1]) + block_size - 1)])
    x <- rbind(x,aux)
  }
  


```

